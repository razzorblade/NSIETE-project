{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final submission- Denoising photos\n",
    "### Enrik Hepner, JÃ¡n Hajzok\n",
    "\n",
    "### Motivation\n",
    "Our motivation for this project is the fact that a neural network could be trained to remove some types of noises and it would be very interesting to observe how it will handle type of noises it did not see yet. Our idea came from our experience with noised and damaged photos, which could be repaired and fixed. It is a very interesting field of research and we are looking forward to work with convolutional neural networks. \n",
    "\n",
    "During the process of learning to work with the CNN we had found it very useful and we had learn a lot. We created more type of noises and we tried to create model, which could be used to denoise all of them. We spent a lot of time to find the best model. We had applied knowledge from related work. Also we had gather a lot of useful advices from the forums online blogs. \n",
    "\n",
    "### Related Work\n",
    "We have been looking for a similar works as ours and the best result we have found are below:\n",
    "* In this article authors had reached a rather good results in image reconstruction from the noised images. They had tried many examples of noise and filters to achieve best results.  \n",
    "Link:https://ieeexplore.ieee.org/abstract/document/6247952\n",
    "\n",
    "\n",
    "\n",
    "* In this article author had compared even more methods of denoising.  \n",
    "Link:https://papers.nips.cc/paper/4686-image-denoising-and-inpainting-with-deep-neural-networks.pdf\n",
    "\n",
    "\n",
    "* This paper use more modern approach for image denoising with interesting layer architecture  \n",
    "Link:https://arxiv.org/pdf/1710.04026.pdf\n",
    "\n",
    "\n",
    "### Datasets\n",
    "There are large databases of image files online. We need two versions of the image, however, the second version which is noised will be created by our algorithm that will add a noise to a default image from the dataset. In case of experimenting with resizing of the image, we need only default one from the image dataset and we can generate the version with artifacts by algorithm.\n",
    "\n",
    "Possible datasets:\n",
    "* Caltech101: http://www.vision.caltech.edu/Image_Datasets/Caltech101/\n",
    "* LSUN Dataset: https://github.com/fyu/lsun\n",
    "* Coco Dataset: http://cocodataset.org/#download\n",
    "\n",
    "Analysis of LSUN Dataset is described in data_analysis.ipynb. During the training, we assumed that we need more diverse types of pictures. Therefore we used Coco Dataset with 10000 images.\n",
    "\n",
    "\n",
    "### High-Level Solution\n",
    "Based on our knowledge from related work documents we have created our own architecture for autoencoder denoising deep neural network. We have used this type because we needed at output the picture with same size as the one at input.\n",
    "\n",
    "### Model\n",
    "At the beginning, we started to train our model with simple autoencoder, which was composed from one covolution layer, one maxpooling layer and one upsampling layer. After study process, we have applied methods of layer order from online articles. From this process we concluded that each convolution layer should be followed by a batch normalization layer, which normalize the activation from previous layer. We have added concatenate layer which groups main output from layer order with some individual layers for better detail at the end of layer assembly. In our project this skip connections had improved quality of output photos significantly. \n",
    "\n",
    "**Convolution layers**: We have used two types of convolutional layers: with 2x2 kernel size and with 3x3 kernel size. In earlier layers, we used 3x3 kernel sizes only, for the purpose of bigger noise presence at the begining of model layers.\n",
    "\n",
    "**MaxPooling**: We have used 2x2 pool size max pooling layer to down-sample input image and reduce its dimensionality.\n",
    "\n",
    "**UpSampling**: 2x2 size layer that will double the dimensions of input, to get a required output dimensionality after using MaxPooling layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Pictures/Untitled Diagram.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training routine\n",
    "\n",
    "#### Architecture\n",
    "We have tried many architectures from available sources and we observed how our autoencoder is improving in denoising chroma noise. With acquired knowledge we developed our architecture dispalyed above. Skip connections and batch normalizations improved our model and its predictions significantly. By using skip connections our model had predicted more accurate output images, that were not blurred.\n",
    "\n",
    "After we were satisfied with tweaking our architecture, we have used it also for other denoising problems:\n",
    "* random shape artifacts\n",
    "* salt and pepper noise\n",
    "* resizing pixel artifacts\n",
    "\n",
    "In every denoising problem we achieved satisfactory prediction results. Therefore our architecture is suitable for noise removal.\n",
    "\n",
    "#### Hyperparameters\n",
    "Firstly, we have tried random hyperparameters for the model. We have analyzed the set of suitable parameters and then used random hyperparameter tunning consisting from this set.\n",
    "\n",
    "Tested hyperparameters:\n",
    "* Optimizers:Adam, Adadelta, Adagrad, SGD, RMSprop\n",
    "* Loss fucntions: categorical_crossentropy, mse, msle\n",
    "* Activation functions: relu, sigmoid, tanh, softmax\n",
    "\n",
    "Best subset of hyperparameters for our model is: Adam, mse, sigmoid\n",
    "\n",
    "We have reached with this subset of hyperparameters validation loss of 0.00196 on noise removal.\n",
    "\n",
    "#### Training\n",
    "Training was performed using google could virtual machine. We have created our own docker image hosted on docker hub, which we also use on virtual machines to ease the environment setup. Hyperparameters tunning was also performed on virtual machine. Hyperparameters were acquired on 1500 samples to speed up the process. With known best hyperparameters we ran it on 10000 samples for noised images, resized images, s&p images and artifacts images. \n",
    "\n",
    "All results are saved in folder logs. We also use model checkpoint as a callback, when fitting the model, so we always have model saved in file based on the best validation loss. To decrease training time we are using early stopping callback, that will stop the training process, if the validation loss is increasing. Another callback we are using is ReduceLROnPlateau, which reduces learning rate when vaidation loss has stopped improving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
