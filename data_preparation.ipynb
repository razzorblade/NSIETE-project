{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random, os\n",
    "import cv2\n",
    "from skimage.exposure import rescale_intensity\n",
    "from skimage import data, color\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from scipy import ndimage\n",
    "from scipy import misc as sm\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from skimage.draw import random_shapes\n",
    "from zipfile import * \n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed();\n",
    "n=5000          #number of images to load\n",
    "img_scale = 128   #scale of the images\n",
    "downscale_dim = 32\n",
    "resize_output_orig= f\"./noise_generation/artifacts_orig/\"      #where to save images\n",
    "resize_output_artifact= f\"./noise_generation/artifacts_changed/\"      #where to save changed images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_files(dir):\n",
    "    \"\"\"Used to recursively iterate through all files in specified dir\"\"\"\n",
    "    files = []\n",
    "    for r, d, f in os.walk(dir):\n",
    "        for file in f:\n",
    "                files.append(os.path.join(r, file))\n",
    "    return files\n",
    "\n",
    "def generate_data(amount, img_scale, dataset_dir, output_orig_dir, output_augmented_dir, process_function):\n",
    "    \"\"\"Generates new data using process_function. New data is loaded as img_scale x img_scale image,\n",
    "         process_function is called on each of these images specified by dataset_dir. Output is split to\n",
    "         output_orig_dir (original files) and output_augmented_dir (processed files).\n",
    "    \"\"\"\n",
    "    rfiles = recursive_files(dataset_dir)\n",
    "\n",
    "    for iteration in range(amount):\n",
    "        rfile = rfiles[iteration]\n",
    "\n",
    "        img = cv2.imread(rfile)\n",
    "        img = resize(img, (img_scale, img_scale), anti_aliasing=True)\n",
    "\n",
    "        img = np.float32(img)\n",
    "\n",
    "        changed = process_function(img)\n",
    "\n",
    "        r_parts = rfile.split('/')\n",
    "        r_end = r_parts[len(r_parts)-1]\n",
    "        no_suffix = r_end.split('.')[0]\n",
    "\n",
    "        cv2.imwrite(f\"{output_orig_dir}{no_suffix}.jpg\", img*256)\n",
    "        cv2.imwrite(f\"{output_augmented_dir}{no_suffix}.jpg\", changed*256)\n",
    "\n",
    "        #print(f\"[{iteration+1}/{amount}] {rfile} -> \", f\"{output_orig_dir}{no_suffix}.jpg\")\n",
    "        #print(f\"[{iteration+1}/{amount}] {rfile} -> \", f\"{output_augmented_dir}{no_suffix}.jpg\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_artifact(img):\n",
    "    max_artifact_size = 13\n",
    "    size = random.randint(8,max_artifact_size)\n",
    "    res, labels = random_shapes((size, size), max_shapes=1, shape='rectangle',multichannel=True)\n",
    "    x_offset=np.random.randint(0, img.shape[0]-max_artifact_size)\n",
    "    y_offset=np.random.randint(0, img.shape[0]-max_artifact_size)\n",
    "    new_img = np.copy(img)\n",
    "    new_img[y_offset:y_offset+res.shape[0], x_offset:x_offset+res.shape[1]] = res*0\n",
    "    return new_img\n",
    "\n",
    "def add_salt_and_pepper(image):\n",
    "    row,col,ch = image.shape\n",
    "    s_vs_p = 0.5\n",
    "    amount = 0.004\n",
    "    out = np.copy(image)\n",
    "    \n",
    "    # Salt mode\n",
    "    num_salt = np.ceil(amount * image.size * s_vs_p)\n",
    "    coords = [np.random.randint(0, i - 1, int(num_salt))for i in image.shape]\n",
    "    out[coords] = 1\n",
    "\n",
    "    # Pepper mode\n",
    "    num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))\n",
    "    coords = [np.random.randint(0, i - 1, int(num_pepper))for i in image.shape]\n",
    "    out[coords] = 0\n",
    "    return out\n",
    "\n",
    "def apply_noise(img):\n",
    "    new_img = np.copy(img)\n",
    "    noise_factor = 0.1\n",
    "    new_img = new_img + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=new_img.shape)\n",
    "    return new_img\n",
    "\n",
    "def apply_artifacts(img):\n",
    "    number_of_artifacts = random.randint(3, 7)\n",
    "    for i in range(number_of_artifacts):\n",
    "        img = add_artifact(img)\n",
    "        \n",
    "    return img\n",
    "\n",
    "output_orig= f\"./noise_generation/artifacts/artifacts_orig/\"             #where to save images\n",
    "output_artifact= f\"./noise_generation/artifacts/artifacts_changed/\"      #where to save changed images\n",
    "dataset_path = \"./noise_generation/artifacts/artifacts_orig/\"\n",
    "img_scale = 128   #scale of images\n",
    "\n",
    "generate_data(5000, img_scale, dataset_path, output_orig, output_artifact, apply_artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
